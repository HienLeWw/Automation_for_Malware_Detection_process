from sklearn.metrics import classification_report, confusion_matrix
from utilities.model.Model import *
import keras
from keras.layers import Dense,Flatten,GlobalAveragePooling1D,Input,Conv1D,MaxPooling1D,Dropout,BatchNormalization,Convolution1D,AveragePooling1D,Conv2D,MaxPooling2D
from keras.utils import to_categorical
from keras.models import Sequential
from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, Callback
from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report, mean_absolute_error
from sklearn.metrics import precision_score, recall_score, accuracy_score
import numpy as np
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from deap import base, creator, tools
import random
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import datetime
import tensorflow as tf

class CNN_Model(Model):
    def __init__(self):
        self.model = None
        self.toolbox = base.Toolbox()
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None

    # Define a function to create individuals with random hyperparameters
    def create_individual(self):
        return [random.uniform(0.0001, 0.01),   # Learning rate
                random.randint(32, 129),        # Batch size
                random.randint(30, 101)]        # Number of epochs
    
    # Define evaluation function
    def evaluate(self, individual):
        learning_rate, batch_size, epochs = individual
        
        # Re-compile the model with new learning rate
        self.model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])

        X_train_cnn = self.X_train.iloc[:, :].values
        y_train_cnn = to_categorical(self.y_train, num_classes=2)
        X_test_cnn = self.X_test.iloc[:, :].values
        y_test_cnn = to_categorical(self.y_test, num_classes=2)
        
        # Train the model
        self.model.fit(X_train_cnn, y_train_cnn, epochs=epochs, batch_size=batch_size, verbose=0)
        
        # Evaluate the model
        accuracy = self.model.evaluate(X_test_cnn, y_test_cnn, verbose=0)[1]

        # # Train the model
        # with tf.device('/CPU:0'):
        #     self.model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size, verbose=0)
        
        # # Evaluate the model
        # accuracy = self.model.evaluate(self.X_test, self.y_test, verbose=0)[1]
        
        return accuracy,

    def evolve_population(self, population, generations):
        for gen in range(generations):
            # Select the next generation of individuals
            offspring = self.toolbox.select(population, len(population))
            
            # Apply crossover and mutation
            offspring = list(map(self.toolbox.clone, offspring))
            for child1, child2 in zip(offspring[::2], offspring[1::2]):
                if random.random() < 0.5:
                    self.toolbox.mate(child1, child2)
                    del child1.fitness.values
                    del child2.fitness.values
            for mutant in offspring:
                if random.random() < 0.2:
                    self.toolbox.mutate(mutant)
                    del mutant.fitness.values
            
            # Evaluate the individuals with invalid fitness
            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]
            fitnesses = map(self.toolbox.evaluate, invalid_ind)
            for ind, fit in zip(invalid_ind, fitnesses):
                ind.fitness.values = fit
            
            # Replace population
            population[:] = offspring

    
    def retrain_model(self, new_data_path):
        # new_data = pd.read_csv(new_data_path)
        super().retrain_model(new_data_path)
        print(self.new_data.shape)
        print(self.new_data['label'].value_counts())
        self.get_metric()
        
        # new_data = new_data[model_features]
        y = self.new_data['label']
        X = self.new_data.drop(columns='label',axis=1)

        # train, test split
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X,y,train_size=0.8,test_size=0.2,random_state=1)

        X_train_cnn = self.X_train.iloc[:, :].values
        y_train_cnn = to_categorical(self.y_train, num_classes=2)
        # X_test_cnn = self.X_test.iloc[:, :].values
        # y_test_cnn = to_categorical(self.y_test, num_classes=2)

        # Define the fitness function and individual structure
        creator.create("FitnessMax", base.Fitness, weights=(1.0,))
        creator.create("Individual", list, fitness=creator.FitnessMax)
        self.toolbox.register("evaluate", self.evaluate)
        self.toolbox.register("individual", tools.initIterate, creator.Individual, self.create_individual)
        self.toolbox.register("population", tools.initRepeat, list, self.toolbox.individual)
        
        # Define mutation and crossover
        self.toolbox.register("mate", tools.cxTwoPoint)
        self.toolbox.register("mutate", tools.mutFlipBit, indpb=0.05)
        self.toolbox.register("select", tools.selTournament, tournsize=3)

        # Initialize population and evolve
        population = self.toolbox.population(n=3)
        self.evolve_population(population, generations=2)

        # Get the best individual after AGA
        best_individual = tools.selBest(population, k=1)[0]
        print(f"Best Hyperparameters (Learning rate, Batch size, Epochs): {best_individual}")
        
        # Retrain with the best hyperparameters
        learning_rate, batch_size, epochs = best_individual

        early_stop = EarlyStopping(monitor='loss',  mode='min',  patience=10, restore_best_weights=True)

        # Retrain with the best hyperparameters
        learning_rate, batch_size, epochs = best_individual
        self.model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])
        self.model.fit(X_train_cnn, y_train_cnn, epochs=epochs, batch_size=batch_size, verbose=1, callbacks=[early_stop])

        # Evaluate final accuracy

        test_data = pd.read_csv('dataset/test_base_data.csv')
        y_test = test_data['label']
        X_test = self.new_data.drop(columns='label',axis=1)

        X_test_cnn = X_test.iloc[:, :].values
        y_test_cnn = to_categorical(y_test, num_classes=2)

        with tf.device('/CPU:0'):
            preds = self.model.predict(X_test_cnn, batch_size=16)

        # with tf.device('/CPU:0'):
        #     preds = self.model.predict(X_test, batch_size=128)
        
        y_pred = np.argmax(preds, axis=1)
        final_accuracy = accuracy_score(y_test, y_pred)
        # final_accuracy = self.model.evaluate(X_test_cnn, y_test_cnn)[1]

        current_date = datetime.date.today()
        print(f"Final Accuracy after AGA: {final_accuracy}")
        if final_accuracy > self.accuracy:
            self.model.save("cnn_"+current_date.strftime("%Y-%m-%d")+".h5")

    def get_metric(self, test_data_path='dataset/test_base_data.csv'):
        self.new_data = pd.read_csv(test_data_path)
        y_test = self.new_data['label']
        X_test = self.new_data.drop(columns='label',axis=1)

        # X_test_cnn = X_test.iloc[:, :-1].values
        X_test_cnn = X_test.iloc[:, :].values

        with tf.device('/CPU:0'):
            # preds = self.model.predict(X_test, batch_size=128)
            preds = self.model.predict(X_test_cnn, batch_size=16)
        
        print(y_test)
        print(preds)
        
        # Calculate metrics
        y_pred = np.argmax(preds, axis=1)
        print(y_pred)

        self.accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

        print('Accuracy: %s\nPrecision: %s\nRecal: %s\nF1-Score: %s' %(self.accuracy, precision, recall, f1))

        
    def get_parameters(self):
        print(self.model.summary())