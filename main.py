import os
import shutil
import subprocess
import sys
import glob
import json
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from utilities.model.Model import *
from utilities.model.CNN_Model import *
from utilities.model.RF_Model import *
from utilities.data.Sample import *
from utilities.data.Dataset import *
import argparse

# Make prediction
def make_predict(input_path, trained_rf_model):
    print("Analysis...")
    
    # Match the sample features with model features
    model_features = trained_rf_model.get_features()
    input_sample = pd.read_csv(input_path)
    new_cols = set(model_features) - set(input_sample.columns)
    for column in new_cols:
        input_sample = input_sample.assign(**{column: 0})

    # Label encode
    s = (input_sample.dtypes == 'object')
    object_cols = list(s[s].index)

    le = LabelEncoder()
    for col in object_cols:
        input_sample[col] = le.fit_transform(input_sample[col].astype('str'))
    input_sample = input_sample[model_features]

    result = trained_rf_model.make_prediction(input_sample)
    if result[0] == 0:
        print("Output: Benign")
    else:
        print("Output: Malware")

def process_dataset(args):
    dataset = DATASET(args.dataset)
    dataset.load_dataset()
    dataset.process()
    if args.visualize:
        dataset.visualize()
    if args.summarize:
        print(dataset.get_summary())
    

def main():
    parser = argparse.ArgumentParser(description='Automation For Android Malware Detection Process Framework')
    parser.add_argument('-f', '--apk', type=str, help='Path to the APK file to be processed')
    parser.add_argument('-m', '--model', type=str, help='Path to the trained model file')
    parser.add_argument('-d', '--dataset', type=str, help='Path to the dataset file')
    parser.add_argument('-r', '--retrain', type=str, help='Retrain model with new data')
    parser.add_argument('-e', '--evaluate', type=str, help='Evaluate the model with test data')
    parser.add_argument('-v', '--visualize', action='store_true', help='Visualize the dataset with PCA, t-SNE & ICA')
    parser.add_argument('-s', '--summarize', action='store_true', help='Summarize the dataset')
    parser.add_argument('-p', '--parameter', action='store_true', help='get model parameters')

    args = parser.parse_args()
    print(args)
    trained_model = Model()
    cnn_model = CNN_Model()
    rf_model = RF_Model()

    if args.model:
        trained_model = Model()
        model_path = args.model
        trained_model.load_model(model_path)
        if 'keras' in str(type(trained_model.model)):
            cnn_model.model = trained_model.model
            print("CNN Loaded!\n")
            if args.retrain:
                cnn_model.retrain_model(args.retrain)
            elif args.evaluate:
                test_data_path = args.evaluate
                cnn_model.get_metric(test_data_path)
            elif args.parameter:
                cnn_model.get_parameters()
            elif args.apk:
                pass
        else:
            rf_model.model = trained_model.model
            print("RF Loaded!\n")
            if args.retrain:
                rf_model.retrain_model(args.retrain)
            elif args.evaluate:
                test_data_path = args.evaluate
                rf_model.get_metric(test_data_path)
            elif args.parameter:
                rf_model.get_parameters()
            elif args.apk:
                apk_file_path = args.apk
                dataset = Sample(apk_file_path)
                sample = dataset.load_sample()
                print(sample)
                make_predict(sample, rf_model)
        
    elif args.dataset:
        process_dataset(args)

    else:
        print("You must provide either both -m (with optional -f -r -e -p) for model processing or -d (with optional -v and -s) for dataset processing.")
        parser.print_help()

if __name__ == "__main__":
    main()
